{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streaming_capymoa import capymoa_classifier, save_results\n",
    "from pham_ensemble_capymoa import PhamEnsemble, save_results_pham\n",
    "from random_projection import create_dataset_RP\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "#Set the current working directory to the script's directory\n",
    "#os.chdir(script_dir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_dir(feature_type, data_dir_imagenet, data_dir_moco, data_dir_moco_ft):\n",
    "    if feature_type=='imagenet':\n",
    "        data_dir = data_dir_imagenet\n",
    "    elif feature_type=='moco':\n",
    "        data_dir = data_dir_moco\n",
    "    elif feature_type=='moco_ft':\n",
    "        data_dir = data_dir_moco_ft\n",
    "    else: raise ValueError(\"The provided feature type is not supported. Please prove imagenet, moco or moco_ft\")\n",
    "    return data_dir\n",
    "\n",
    "def results_to_df(classifier_capymoa, results_df, time_rp, no_RP = False):\n",
    "    if results_df is None:\n",
    "        column_names = ['classifier', 'features', 'k', 'type_RP', 'no_RP','prequential', 'in_domain', 'next_domain', 'ft', 'bt',\n",
    "                         'time_classifier', 'time_ft', 'time_bt', 'seed', 'time_rp']\n",
    "        results_df = pd.DataFrame(columns=column_names)\n",
    "    new_row = {}\n",
    "    new_row['classifier'] = classifier_capymoa.classifier\n",
    "    new_row['features'] = classifier_capymoa.rp_settings['features']\n",
    "    new_row['k'] = classifier_capymoa.rp_settings['n_reduced']\n",
    "    new_row['type_RP'] = classifier_capymoa.rp_settings['type_RP']\n",
    "    new_row['no_RP'] = no_RP    \n",
    "    new_row['prequential'] = classifier_capymoa.result_cumulative_pd['accuracy'].iloc[-1]\n",
    "    new_row['in_domain'] = classifier_capymoa.in_domain_acc\n",
    "    new_row['next_domain'] = classifier_capymoa.next_domain_acc\n",
    "    new_row['ft'] = classifier_capymoa.ft_acc\n",
    "    new_row['bt'] = classifier_capymoa.bt_acc\n",
    "    new_row['time_classifier'] = classifier_capymoa.time_classifier/60\n",
    "    new_row['time_ft'] = classifier_capymoa.time_ft/60\n",
    "    new_row['time_bt'] = classifier_capymoa.time_bt/60\n",
    "    new_row['seed'] = classifier_capymoa.seed\n",
    "    new_row['time_rp'] = time_rp\n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    results_df = pd.concat([results_df, new_row_df], ignore_index=True)\n",
    "    return(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multiple_runs_k_values(superclass_dict, rp_types, feature_types, seeds, classifiers, model_names, k_values, data_dirs, folder_save,\n",
    "                            save_df, first_exp=0, nexp=11):\n",
    "    results_df = None\n",
    "    idx=0\n",
    "    for feature_type in feature_types:\n",
    "        data_dir = retrieve_data_dir(feature_type=feature_type, data_dir_imagenet=data_dirs['imagenet'], data_dir_moco=data_dirs['moco'],\n",
    "                                      data_dir_moco_ft=data_dirs['moco_ft'])\n",
    "        for classifier in classifiers:\n",
    "            for rp_type in rp_types:\n",
    "                for k in k_values:\n",
    "                    rp_settings = {\n",
    "                        'n_reduced': k,\n",
    "                        'type_RP': rp_type,\n",
    "                        'features': feature_type\n",
    "                    }\n",
    "\n",
    "                    for seed in seeds:\n",
    "                        # data directory in which projected data are saved\n",
    "                        save_dir = folder_save +'/k_values/rp_dataset/rp_' + feature_type + '_' + rp_type + '_k=' + str(k) + '_seed_' + str(seed)\n",
    "                        #print(save_dir)\n",
    "                        if not os.path.exists(save_dir):\n",
    "                            os.makedirs(save_dir)\n",
    "                        # project data via random projection\n",
    "                        time_RP = create_dataset_RP(data_dir=data_dir, save_dir = save_dir, split_data=False, n_original=2048, \n",
    "                                                    n_reduced=rp_settings['n_reduced'], type_RP=rp_settings['type_RP'], seed=seed, nexp=nexp)        \n",
    "                        \n",
    "                        dir_save_models = folder_save + '/models/k_values_' +classifier + '_'+ feature_type + '_' + rp_type + '_k=' + str(k) + '_seed_' + str(seed)\n",
    "                        if not os.path.exists(dir_save_models):\n",
    "                            os.makedirs(dir_save_models)\n",
    "\n",
    "                        \n",
    "                        # initialize the classifier\n",
    "                        classifier_to_run=capymoa_classifier(classifier=classifier, rp_settings=rp_settings, nexp=nexp, window_size=None, first_exp=first_exp,\n",
    "                                                            superclass_dict=superclass_dict, model_name = model_names[classifier], seed=seed, data_dir=save_dir+'/all',\n",
    "                                                            dir_save_models = dir_save_models)\n",
    "                        # run the model\n",
    "                        classifier_to_run.run_model(show_accuracy=False, show_confusion=False, compute_ft=True, show_ft=False, compute_bt=True)\n",
    "\n",
    "                        # save the relevant results\n",
    "                        filename_results_save = classifier + '_'+ feature_type + '_' + rp_type + '_k=' + str(k) + '_seed_' + str(seed)\n",
    "                        save_results(classifier_capymoa=classifier_to_run, folder_save=folder_save, filename_save=filename_results_save)\n",
    "                        results_df = results_to_df(classifier_capymoa=classifier_to_run, results_df=results_df, time_rp=time_RP, no_RP=False)\n",
    "                        results_df.to_csv(folder_save +'/'+ save_df+ str(idx) + '.csv', index=False)\n",
    "                        idx+=1\n",
    "\n",
    "    results_df.to_csv(folder_save +'/'+ save_df+ '.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_runs_Pham(superclass_dict, rp_types, feature_types, seeds, classifiers, k_values, n_models, data_dirs, folder_save,\n",
    "                            save_df, first_exp=0, nexp=11):\n",
    "    results_df = None\n",
    "\n",
    "    for feature_type in feature_types:\n",
    "        data_dir = retrieve_data_dir(feature_type=feature_type, data_dir_imagenet=data_dirs['imagenet'], data_dir_moco=data_dirs['moco'],\n",
    "                                      data_dir_moco_ft=data_dirs['moco_ft'])\n",
    "        for classifier in classifiers:\n",
    "            for rp_type in rp_types:\n",
    "                for k in k_values:\n",
    "                    rp_settings = {\n",
    "                        'n_reduced': k,\n",
    "                        'type_RP': rp_type,\n",
    "                        'features': feature_type,\n",
    "                        'n_original':2048\n",
    "                    }\n",
    "\n",
    "                    for seed in seeds:        \n",
    "                        dir_save_models = folder_save + '/models/k_values_' +classifier + '_'+ feature_type + '_' + rp_type + '_k=' + str(k) + '_seed_' + str(seed)\n",
    "                        if not os.path.exists(dir_save_models):\n",
    "                            os.makedirs(dir_save_models)\n",
    "\n",
    "                        \n",
    "                        # initialize the classifier\n",
    "                        classifier_to_run = PhamEnsemble(classifier=classifier, n_models = n_models, class_dict = superclass_dict, rp_settings=rp_settings,\n",
    "                                                         save_dir_models=dir_save_models, data_dir=data_dir, nexp=nexp, first_exp=first_exp, seed = seed)\n",
    "\n",
    "                        # run the model\n",
    "                        classifier_to_run.run_model(show_accuracy=False, show_confusion=False, compute_ft=True, compute_bt=True)\n",
    "\n",
    "                        # save the relevant results\n",
    "                        filename_results_save = 'Pham_' + classifier + '_'+ feature_type + '_' + rp_type + '_k=' + str(k) + '_seed_' + str(seed)\n",
    "                        save_results_pham(classifier_capymoa=classifier_to_run, folder_save=folder_save, filename_save=filename_results_save)\n",
    "                        results_df = results_to_df(classifier_capymoa=classifier_to_run, results_df=results_df, time_rp=0, no_RP=False)\n",
    "                        results_df.to_csv(folder_save +'/'+ save_df+ '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = {\n",
    "    'imagenet': 'feature_extraction/features_imagenet_seed2024/all',\n",
    "    'moco': 'feature_extraction/features_moco_seed2024/all',\n",
    "    'moco_ft': 'feature_extraction/features_moco_ft_seed2024/all'\n",
    "}\n",
    "\n",
    "superclass_dict = {\n",
    "    0: 'airplane',\n",
    "    1: 'amusement_park',\n",
    "    2: 'anime',\n",
    "    3: 'aquarium',\n",
    "    4: 'backpack',\n",
    "    5: 'baseball',\n",
    "    6: 'basketball',\n",
    "    7: 'bathroom',\n",
    "    8: 'beer',\n",
    "    9: 'bicycle',\n",
    "    10: 'billard',\n",
    "    11: 'billboard',\n",
    "    12: 'blackboard',\n",
    "    13: 'boat',\n",
    "    14: 'bookstore',\n",
    "    15: 'bowling_ball',\n",
    "    16: 'bridge',\n",
    "    17: 'bus',\n",
    "    18: 'camera',\n",
    "    19: 'canned_food',\n",
    "    20: 'casino',\n",
    "    21: 'castle',\n",
    "    22: 'chef',\n",
    "    23: 'chocolate',\n",
    "    24: 'church',\n",
    "    25: 'coins',\n",
    "    26: 'coser',\n",
    "    27: 'diving',\n",
    "    28: 'farm',\n",
    "    29: 'ferry',\n",
    "    30: 'field_hockey',\n",
    "    31: 'firefighter',\n",
    "    32: 'food_truck',\n",
    "    33: 'football',\n",
    "    34: 'fountain',\n",
    "    35: 'gallery',\n",
    "    36: 'garage',\n",
    "    37: 'glasses',\n",
    "    38: 'gloves',\n",
    "    39: 'golf',\n",
    "    40: 'graffiti',\n",
    "    41: 'guitar',\n",
    "    42: 'gym',\n",
    "    43: 'hair_salon',\n",
    "    44: 'hat',\n",
    "    45: 'helicopter',\n",
    "    46: 'highway',\n",
    "    47: 'horse_riding',\n",
    "    48: 'ice_cream',\n",
    "    49: 'ice_hockey',\n",
    "    50: 'ice_skating',\n",
    "    51: 'lab',\n",
    "    52: 'lamppost',\n",
    "    53: 'laptop',\n",
    "    54: 'laundry',\n",
    "    55: 'lego',\n",
    "    56: 'microphone',\n",
    "    57: 'motorcycle',\n",
    "    58: 'mug',\n",
    "    59: 'necklaces',\n",
    "    60: 'newspaper',\n",
    "    61: 'observatory',\n",
    "    62: 'opera_house',\n",
    "    63: 'pet_store',\n",
    "    64: 'piano',\n",
    "    65: 'plush_toys',\n",
    "    66: 'policeman',\n",
    "    67: 'power_plant',\n",
    "    68: 'racing_car',\n",
    "    69: 'ring',\n",
    "    70: 'road_sign',\n",
    "    71: 'robot',\n",
    "    72: 'roller_skate',\n",
    "    73: 'scarf',\n",
    "    74: 'shopping_mall',\n",
    "    75: 'skateboarding',\n",
    "    76: 'skiing',\n",
    "    77: 'skyscraper',\n",
    "    78: 'soccer',\n",
    "    79: 'soldier',\n",
    "    80: 'stadium',\n",
    "    81: 'statue',\n",
    "    82: 'subway',\n",
    "    83: 'supermarket',\n",
    "    84: 'surfing',\n",
    "    85: 'swimming',\n",
    "    86: 'table_tennis',\n",
    "    87: 'temple',\n",
    "    88: 'tennis',\n",
    "    89: 'tie',\n",
    "    90: 'tractor',\n",
    "    91: 'train',\n",
    "    92: 'umbrella',\n",
    "    93: 'vase',\n",
    "    94: 'vending_machine',\n",
    "    95: 'video_game',\n",
    "    96: 'violin',\n",
    "    97: 'volleyball',\n",
    "    98: 'watch',\n",
    "    99: 'zoo'\n",
    "}\n",
    "superclass_labels = superclass_dict.keys()\n",
    "\n",
    "model_names = {\n",
    "    'nb': 'Naive Bayes',\n",
    "    'ht': 'Hoeffding tree',\n",
    "    'hat': 'Hoeffding adaptive tree',\n",
    "    'ht2': 'Hoeffding tree',\n",
    "    'hat2': 'Hoeffding adaptive tree',\n",
    "    'knn': 'KNN',\n",
    "    'knn2': 'Online KNN',\n",
    "    'sgd2': 'Softmax regression - SGD',\n",
    "    'ob_ht': 'Online bagging',\n",
    "    'lb_ht': 'Leveraging bagging',\n",
    "    'oza': 'OzaBoost',\n",
    "    'ozaboost': 'OzaBoost'\n",
    "}\n",
    "\n",
    "first_exp=0\n",
    "nexp=11\n",
    "folder_save = 'k_values'\n",
    "\n",
    "\n",
    "save_df = 'knn2_very_sparse_imagenet_k=100_ft_bt_seed_2024'\n",
    "rp_types = ['very sparse']\n",
    "feature_types = ['imagenet']\n",
    "seeds = [2024]\n",
    "classifiers = ['knn2']\n",
    "k_values = [100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_runs_k_values(superclass_dict=superclass_dict, rp_types=rp_types, feature_types=feature_types, seeds=seeds, classifiers=classifiers, \n",
    "                       model_names=model_names, k_values=k_values, data_dirs=data_dirs, folder_save=folder_save, first_exp=first_exp, nexp=nexp, \n",
    "                       save_df=save_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_types = ['sparse']\n",
    "feature_types = ['moco']\n",
    "seeds = [2024]\n",
    "classifiers = ['ht']\n",
    "k_values = [100]\n",
    "n_models = 10\n",
    "folder_save = 'Pham'\n",
    "save_df = 'Pham_moco_k=100'\n",
    "\n",
    "multiple_runs_Pham(superclass_dict=superclass_dict, rp_types=rp_types, feature_types=feature_types, seeds=seeds, \n",
    "                   classifiers=classifiers, k_values=k_values, n_models=n_models, data_dirs=data_dirs, folder_save=folder_save,\n",
    "                            save_df=save_df, first_exp=0, nexp=11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
